# ğŸ©º ClasificaciÃ³n MÃ©dica â€“ OptimizaciÃ³n de Modelos (MÃ³dulo 4)

## ğŸ“– DescripciÃ³n General

Este proyecto corresponde a la **Actividad de la SesiÃ³n 2 del MÃ³dulo 4** del curso de *Machine Learning*, cuyo objetivo fue **construir un modelo de clasificaciÃ³n mÃ©dica** para predecir la probabilidad de diabetes en pacientes, utilizando el dataset **Pima Indians Diabetes Dataset**.

A partir de este conjunto de datos, se entrenaron modelos de **Random Forest** aplicando distintas estrategias de optimizaciÃ³n de hiperparÃ¡metros para mejorar su desempeÃ±o.

---

## ğŸ“‚ Contenido del Repositorio

| Archivo | DescripciÃ³n |
|----------|--------------|
| `Act2M4_MHZ.ipynb` | ImplementaciÃ³n de un modelo base con **RandomForestClassifier**, seguido de **Grid Search** y **Random Search**. Incluye anÃ¡lisis comparativo de mÃ©tricas y tiempos de ejecuciÃ³n. |
| `Act2M4Optuna.ipynb` | VersiÃ³n extendida donde se utiliza **Optuna** para la optimizaciÃ³n automÃ¡tica de hiperparÃ¡metros. Se compara su rendimiento con las estrategias anteriores. |
| `README.md` | Documento explicativo del proyecto y reflexiÃ³n personal. |

---

## âš™ï¸ Decisiones TÃ©cnicas

- **Modelo base:** Se eligiÃ³ `RandomForestClassifier` por su estabilidad, facilidad de uso y buen rendimiento en tareas de clasificaciÃ³n mÃ©dica.
- **Preprocesamiento:** Se aplicÃ³ `StandardScaler` para escalar las variables numÃ©ricas y se dividieron los datos en entrenamiento (70%) y prueba (30%).
- **OptimizaciÃ³n de hiperparÃ¡metros:**
  - **Grid Search:** Se definiÃ³ una malla de combinaciones fijas de parÃ¡metros (`n_estimators`, `max_depth`, `min_samples_split`), buscando el mejor conjunto mediante bÃºsqueda exhaustiva.
  - **Random Search:** Se probaron combinaciones aleatorias dentro de rangos mÃ¡s amplios, reduciendo significativamente el tiempo de cÃ³mputo.
  - **Optuna:** En el segundo notebook, se explorÃ³ una alternativa mÃ¡s automatizada, capaz de encontrar configuraciones Ã³ptimas mediante tÃ©cnicas de *sampling* y *pruning*.
- **EvaluaciÃ³n del modelo:** Se utilizaron mÃ©tricas de desempeÃ±o como *accuracy*, *recall*, *F1-score* y *AUC*, junto con el tiempo de ejecuciÃ³n para comparar eficiencia.

---

## ğŸ“Š Resultados Principales

| MÃ©todo | Accuracy | F1-Score | Tiempo (s) | ObservaciÃ³n |
|--------|-----------|----------|-------------|--------------|
| Modelo Base | Medio | Medio | Bajo | Modelo sin optimizaciÃ³n |
| Grid Search | Alto | Alto | Mayor | PrecisiÃ³n mejorada, pero mayor tiempo de cÃ³mputo |
| Random Search | Similar o mejor | Similar o mejor | Menor | Equilibrio entre desempeÃ±o y eficiencia |
| Optuna | Mejor | Mejor | Razonable | Excelente balance entre rendimiento y tiempo |

---

## ğŸ’­ ReflexiÃ³n Final

> Esta actividad me ayudÃ³ a entender de forma prÃ¡ctica cÃ³mo los **hiperparÃ¡metros influyen directamente en el rendimiento de los modelos**.  
> Al principio me costÃ³ visualizar por quÃ© era necesario ajustar tantos parÃ¡metros, pero al comparar los mÃ©todos comprendÃ­ que **no solo se trata de encontrar el mejor modelo, sino tambiÃ©n de hacerlo de manera eficiente**.  
>
> Me sorprendiÃ³ que el **Random Search** lograra resultados muy cercanos al Grid Search en mucho menos tiempo, y que herramientas como **Optuna** puedan automatizar aÃºn mÃ¡s ese proceso.  
>
> En el futuro me gustarÃ­a explorar otros modelos y probar estrategias mÃ¡s avanzadas de optimizaciÃ³n, pero esta experiencia me dio una base sÃ³lida sobre cÃ³mo enfrentar los ajustes de modelos en Machine Learning y cÃ³mo evaluar su desempeÃ±o de forma mÃ¡s crÃ­tica. ğŸš€

---

## ğŸ§  TecnologÃ­as y LibrerÃ­as

- Python 3.x  
- Scikit-learn  
- Optuna  
- Pandas  
- Numpy  
- Matplotlib / Seaborn  

---

## ğŸ‘©â€ğŸ’» Autora

**Mary H. Z.**  
Proyecto desarrollado como parte del curso *Machine Learning â€“ MÃ³dulo 4*  
(Actividad de ajuste de hiperparÃ¡metros y optimizaciÃ³n de modelos)
